{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!python3 -m  pip install mlc-ai-cpu -f https://mlc.ai/wheels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYS-TPdVO80L",
        "outputId": "5ff5586d-059c-4986-bce4-666c6236ff34"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://mlc.ai/wheels\n",
            "Collecting mlc-ai-cpu\n",
            "  Downloading https://github.com/mlc-ai/package/releases/download/v0.9.dev0/mlc_ai_cpu-0.17.2-cp310-cp310-manylinux_2_28_x86_64.whl (185.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.8/185.8 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (24.2.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (3.1.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (4.4.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (1.13.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (6.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (4.12.2)\n",
            "Installing collected packages: mlc-ai-cpu\n",
            "Successfully installed mlc-ai-cpu-0.17.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QPtwkVrnwWX",
        "outputId": "90f3ba9c-22fc-4d87-bf24-aee2f7ef787f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LPRNet_CSC591'...\n",
            "remote: Enumerating objects: 1087, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 1087 (delta 33), reused 34 (delta 25), pack-reused 1037 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1087/1087), 20.46 MiB | 18.84 MiB/s, done.\n",
            "Resolving deltas: 100% (43/43), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone -b dev_chirag https://github.com/chiragbheemaiah/LPRNet_CSC591.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd LPRNet_CSC591"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8pa3QARog1c",
        "outputId": "dfe0956a-03d4-4aa4-dbcf-eaa92bdb3c01"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LPRNet_CSC591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tvm\n",
        "from tvm import relay\n",
        "from tvm.runtime import load_param_dict\n",
        "from tvm.contrib import graph_executor\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "ZPmNES-l5DR9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Function"
      ],
      "metadata": {
        "id": "t6gjVOqMPZXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from types import SimpleNamespace\n",
        "\n",
        "args = {\n",
        "    'img_size': [94, 24],\n",
        "    'test_img_dirs': \"./data/test\",\n",
        "    'dropout_rate': 0,\n",
        "    'lpr_max_len': 8,\n",
        "    'test_batch_size': 100,\n",
        "    'phase_train': False,\n",
        "    'num_workers': 8,\n",
        "    'cuda': False,\n",
        "    'show': False,\n",
        "    'pretrained_model': './weights/Final_LPRNet_model.pth'\n",
        "}\n",
        "\n",
        "args = SimpleNamespace(**args)"
      ],
      "metadata": {
        "id": "omL9-B6w5bxs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from data.load_data import CHARS, CHARS_DICT, LPRDataLoader\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from model.LPRNet import build_lprnet\n",
        "# import torch.backends.cudnn as cudnn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import *\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import argparse\n",
        "import torch\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def collate_fn(batch):\n",
        "    imgs = []\n",
        "    labels = []\n",
        "    lengths = []\n",
        "    for _, sample in enumerate(batch):\n",
        "        img, label, length = sample\n",
        "        imgs.append(torch.from_numpy(img))\n",
        "        labels.extend(label)\n",
        "        lengths.append(length)\n",
        "    labels = np.asarray(labels).flatten().astype(np.float32)\n",
        "\n",
        "    return (torch.stack(imgs, 0), torch.from_numpy(labels), lengths)\n",
        "\n",
        "def test(module):\n",
        "    test_img_dirs = os.path.expanduser(args.test_img_dirs)\n",
        "    test_dataset = LPRDataLoader(test_img_dirs.split(','), args.img_size, args.lpr_max_len)\n",
        "    Greedy_Decode_Eval(module, test_dataset, args)\n",
        "\n",
        "def Greedy_Decode_Eval(module, datasets, args):\n",
        "    # TestNet = Net.eval()\n",
        "    epoch_size = len(datasets) // args.test_batch_size\n",
        "    batch_iterator = iter(DataLoader(datasets, args.test_batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=collate_fn))\n",
        "\n",
        "    Tp = 0\n",
        "    Tn_1 = 0\n",
        "    Tn_2 = 0\n",
        "    t1 = time.time()\n",
        "    for i in range(epoch_size):\n",
        "        # load train data\n",
        "        images, labels, lengths = next(batch_iterator)\n",
        "        start = 0\n",
        "        targets = []\n",
        "        for length in lengths:\n",
        "            label = labels[start:start+length]\n",
        "            targets.append(label)\n",
        "            start += length\n",
        "        targets = np.array([el.numpy() for el in targets])\n",
        "        imgs = images.numpy().copy()\n",
        "\n",
        "        if args.cuda:\n",
        "            images = Variable(images.cuda())\n",
        "        else:\n",
        "            images = Variable(images)\n",
        "\n",
        "        # forward\n",
        "        # prebs = Net(images)\n",
        "        # Set input and run\n",
        "        module.set_input(input_name, tvm.nd.array(images.numpy()))\n",
        "        module.run()\n",
        "\n",
        "        # Get output\n",
        "        tvm_output = module.get_output(0).asnumpy()\n",
        "        print(\"Output shape:\", tvm_output.shape)\n",
        "        prebs = tvm_output\n",
        "        # greedy decode\n",
        "        # prebs = prebs.cpu().detach().numpy()\n",
        "        preb_labels = list()\n",
        "        for i in range(prebs.shape[0]):\n",
        "            preb = prebs[i, :, :]\n",
        "            preb_label = list()\n",
        "            for j in range(preb.shape[1]):\n",
        "                preb_label.append(np.argmax(preb[:, j], axis=0))\n",
        "            no_repeat_blank_label = list()\n",
        "            pre_c = preb_label[0]\n",
        "            if pre_c != len(CHARS) - 1:\n",
        "                no_repeat_blank_label.append(pre_c)\n",
        "            for c in preb_label: # dropout repeate label and blank label\n",
        "                if (pre_c == c) or (c == len(CHARS) - 1):\n",
        "                    if c == len(CHARS) - 1:\n",
        "                        pre_c = c\n",
        "                    continue\n",
        "                no_repeat_blank_label.append(c)\n",
        "                pre_c = c\n",
        "            preb_labels.append(no_repeat_blank_label)\n",
        "        for i, label in enumerate(preb_labels):\n",
        "            # show image and its predict label\n",
        "            # if args.show:\n",
        "                # show(imgs[i], label, targets[i])\n",
        "            if len(label) != len(targets[i]):\n",
        "                Tn_1 += 1\n",
        "                continue\n",
        "            if (np.asarray(targets[i]) == np.asarray(label)).all():\n",
        "                Tp += 1\n",
        "            else:\n",
        "                Tn_2 += 1\n",
        "    Acc = Tp * 1.0 / (Tp + Tn_1 + Tn_2)\n",
        "    print(\"[Info] Test Accuracy: {} [{}:{}:{}:{}]\".format(Acc, Tp, Tn_1, Tn_2, (Tp+Tn_1+Tn_2)))\n",
        "    t2 = time.time()\n",
        "    print(\"[Info] Test Speed: {}s 1/{}]\".format((t2 - t1) / len(datasets), len(datasets)))\n"
      ],
      "metadata": {
        "id": "3L5huP8aPT_r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = \"llvm\"\n",
        "dev = tvm.cuda(0) if target == \"cuda\" else tvm.cpu()"
      ],
      "metadata": {
        "id": "mMvkzrv-4_un"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (args.test_batch_size, 3, 24, 94)\n",
        "input_name = \"input0\""
      ],
      "metadata": {
        "id": "-chyEQYf5pD7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "# Load the compiled module\n",
        "module_path = \"/content/module.tar\"\n",
        "loaded_lib = tvm.runtime.load_module(module_path)\n",
        "\n",
        "# Create a GraphModule runtime\n",
        "dev = tvm.device(str(target), 0)\n",
        "runtime_module = graph_executor.GraphModule(loaded_lib[\"default\"](dev))\n",
        "\n",
        "# Load PyTorch weights\n",
        "pth_file = \"/content/lprnet_quantized_and_pruned_weights.pth\"\n",
        "torch_weights = torch.load(pth_file)\n",
        "# Dequantize and load the weights into the model\n",
        "dequantized_state_dict = OrderedDict()\n",
        "for key, value in torch_weights.items():\n",
        "    if 'scale' in key or 'zero_point' in key:\n",
        "        continue\n",
        "    if value.is_quantized:\n",
        "        dequantized_state_dict[key] = value.dequantize()\n",
        "    else:\n",
        "        dequantized_state_dict[key] = value\n",
        "# Convert PyTorch weights to TVM NDArray format\n",
        "new_params = {}\n",
        "for key, value in dequantized_state_dict.items():\n",
        "    # Convert PyTorch tensors to NumPy arrays, then to TVM NDArrays\n",
        "    new_params[key] = tvm.nd.array(value.cpu().detach().numpy())\n",
        "print(\"Weights converted for TVM.\")\n",
        "\n",
        "# Serialize the weights into a binary format\n",
        "from tvm.relay import save_param_dict\n",
        "param_bytes = save_param_dict(new_params)\n",
        "\n",
        "# Replace the weights in the runtime using serialized weights\n",
        "runtime_module.load_params(param_bytes)\n",
        "print(\"Weights replaced successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzATeIfizYWU",
        "outputId": "6a35532b-69f6-4a19-eaaa-c747060aeaab"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-34db3571d053>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  torch_weights = torch.load(pth_file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights converted for TVM.\n",
            "Weights replaced successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(runtime_module)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjwjEhaUmSKZ",
        "outputId": "d75b5db5-bc61-42c9-af7d-f9ccf5d0b34f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "[Info] Test Accuracy: 0.9 [900:58:42:1000]\n",
            "[Info] Test Speed: 0.03699205112457275s 1/1000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python /content/LPRNet_CSC591/test_LPRNet.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwVEXkKCh7uH",
        "outputId": "4f741d81-9469-44f6-98e4-8b2e47241c1a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful to build network!\n",
            "/content/LPRNet_CSC591/test_LPRNet.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  lprnet.load_state_dict(torch.load(args.pretrained_model, map_location=torch.device('cpu')))\n",
            "load pretrained model successful!\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[Info] Test Accuracy: 0.899 [899:61:40:1000]\n",
            "[Info] Test Speed: 0.20774351835250854s 1/1000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gg4hN3b65UXJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}