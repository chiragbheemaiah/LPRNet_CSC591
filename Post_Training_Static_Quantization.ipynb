{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATD-45w_oSMu"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdfCUFf5TGDR",
        "outputId": "b789224a-73d4-45a6-d2b9-6c83e2369089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LPRNet_CSC591'...\n",
            "remote: Enumerating objects: 1099, done.\u001b[K\n",
            "remote: Counting objects: 100% (62/62), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 1099 (delta 39), reused 42 (delta 29), pack-reused 1037 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1099/1099), 21.34 MiB | 16.67 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/chiragbheemaiah/LPRNet_CSC591.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNnqDgZCWm1O",
        "outputId": "f23db16d-9c7a-4602-9f3d-0639792aedb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LPRNet_CSC591\n"
          ]
        }
      ],
      "source": [
        "cd LPRNet_CSC591"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws2Zo-LVonvO"
      },
      "source": [
        "## Baseline Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRdWn0M2WyEi",
        "outputId": "45143d1c-aa71-491d-8b5b-bc42c5abb080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful to build network!\n",
            "/content/LPRNet_CSC591/test_LPRNet.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  lprnet.load_state_dict(torch.load(args.pretrained_model, map_location=torch.device('cpu')))\n",
            "load pretrained model successful!\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[Info] Test Accuracy: 0.899 [899:58:43:1000]\n",
            "[Info] Test Speed: 0.2044245445728302s 1/1000]\n"
          ]
        }
      ],
      "source": [
        "! python test_LPRNet.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzUikxzJoOsV"
      },
      "source": [
        "# Model Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oL1BDzsJX8U-"
      },
      "outputs": [],
      "source": [
        "from data.load_data import CHARS, CHARS_DICT, LPRDataLoader\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from model.LPRNet import build_lprnet\n",
        "# import torch.backends.cudnn as cudnn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import *\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import argparse\n",
        "import torch\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "import copy\n",
        "from types import SimpleNamespace\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SB9af3U_CNoY"
      },
      "outputs": [],
      "source": [
        "args = {\n",
        "    'img_size': [94, 24],\n",
        "    'test_img_dirs': \"./data/test\",\n",
        "    'dropout_rate': 0,\n",
        "    'lpr_max_len': 8,\n",
        "    'test_batch_size': 100,\n",
        "    'phase_train': False,\n",
        "    'num_workers': 8,\n",
        "    'cuda': False,\n",
        "    'show': False,\n",
        "    'pretrained_model': './weights/pruned_model_weights_trial2.pth'\n",
        "}\n",
        "\n",
        "args = SimpleNamespace(**args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "h6ERiAUafbOu"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class small_basic_block(nn.Module):\n",
        "    def __init__(self, ch_in, ch_out):\n",
        "        super(small_basic_block, self).__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(ch_in, ch_out // 4, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(ch_out // 4, ch_out // 4, kernel_size=(3, 1), padding=(1, 0)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(ch_out // 4, ch_out // 4, kernel_size=(1, 3), padding=(0, 1)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(ch_out // 4, ch_out, kernel_size=1),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class LPRNet(nn.Module):\n",
        "    def __init__(self, lpr_max_len, phase, class_num, dropout_rate):\n",
        "        super(LPRNet, self).__init__()\n",
        "        self.phase = phase\n",
        "        self.lpr_max_len = lpr_max_len\n",
        "        self.class_num = class_num\n",
        "        self.backbone = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1), # 0\n",
        "            nn.BatchNorm2d(num_features=64),\n",
        "            nn.ReLU(),  # 2\n",
        "            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 1, 1)),\n",
        "            small_basic_block(ch_in=64, ch_out=128),    # *** 4 ***\n",
        "            nn.BatchNorm2d(num_features=128),\n",
        "            nn.ReLU(),  # 6\n",
        "            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(2, 1, 2)),\n",
        "            small_basic_block(ch_in=64, ch_out=256),   # 8\n",
        "            nn.BatchNorm2d(num_features=256),\n",
        "            nn.ReLU(),  # 10\n",
        "            small_basic_block(ch_in=256, ch_out=256),   # *** 11 ***\n",
        "            nn.BatchNorm2d(num_features=256),   # 12\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(4, 1, 2)),  # 14\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Conv2d(in_channels=64, out_channels=256, kernel_size=(1, 4), stride=1),  # 16\n",
        "            nn.BatchNorm2d(num_features=256),\n",
        "            nn.ReLU(),  # 18\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Conv2d(in_channels=256, out_channels=class_num, kernel_size=(13, 1), stride=1), # 20\n",
        "            nn.BatchNorm2d(num_features=class_num),\n",
        "            nn.ReLU(),  # *** 22 ***\n",
        "        )\n",
        "        self.container = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=448+self.class_num, out_channels=self.class_num, kernel_size=(1, 1), stride=(1, 1)),\n",
        "            # nn.BatchNorm2d(num_features=self.class_num),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Conv2d(in_channels=self.class_num, out_channels=self.lpr_max_len+1, kernel_size=3, stride=2),\n",
        "            # nn.ReLU(),\n",
        "        )\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"in forward of lprnet\")\n",
        "        keep_features = list()\n",
        "        x = self.quant(x)\n",
        "        for i, layer in enumerate(self.backbone.children()):\n",
        "            # print(f\"Layer {i}: {layer}\")  # Print layer information for debugging\n",
        "\n",
        "            # Check if layer is MaxPool3d and print input shape before applying it\n",
        "            if isinstance(layer, nn.MaxPool3d):\n",
        "                # print(f\"Input shape before MaxPool3d: {x.shape}\")\n",
        "                x = x.unsqueeze(0)  # Add a new dimension at index 2 to make it 5D\n",
        "\n",
        "            x = layer(x)\n",
        "\n",
        "            # Reshape back to 4D after MaxPool3d\n",
        "            if isinstance(layer, nn.MaxPool3d):\n",
        "              # print(f\"Output shape after MaxPool3d: {x.shape}\")\n",
        "\n",
        "              x = x.squeeze(0)  # Remove the added dimension to make it 4D again\n",
        "              # print(f\"Output shape after MaxPool3d after squeeze: {x.shape}\")\n",
        "\n",
        "            if i in [2, 6, 13, 22]: # [2, 4, 8, 11, 22]\n",
        "                keep_features.append(self.dequant(x))\n",
        "        # requantize = False\n",
        "        global_context = list()\n",
        "        for i, f in enumerate(keep_features):\n",
        "            if i in [0, 1]:\n",
        "                f = nn.AvgPool2d(kernel_size=5, stride=5)(f)\n",
        "            if i in [2]:\n",
        "                f = nn.AvgPool2d(kernel_size=(4, 10), stride=(4, 2))(f)\n",
        "\n",
        "            # if f.is_quantized:\n",
        "            #   f = torch.dequantize(f)\n",
        "            #   requantize = True\n",
        "            f_pow = torch.pow(f, 2)\n",
        "            f_mean = torch.mean(f_pow)\n",
        "            f = torch.div(f, f_mean)\n",
        "            global_context.append(f)\n",
        "        x = self.dequant(x)\n",
        "        # print(x.shape)\n",
        "        x = torch.cat(global_context, 1)\n",
        "        # print(x.shape)\n",
        "        x = self.container(x)\n",
        "        # print(x.shape)\n",
        "        logits = torch.mean(x, dim=2)\n",
        "        # print(logits.shape)\n",
        "        # x = torch.cat(global_context, 1)\n",
        "        # if requantize:\n",
        "        #   x = torch.quantize_per_tensor(x, scale=0.0157, zero_point=64, dtype=torch.quint8) # Example with float, int, and dtype\n",
        "        #   requantize = False\n",
        "        # x = self.container(x)\n",
        "        # logits = torch.mean(x, dim=2)\n",
        "\n",
        "        return logits\n",
        "\n",
        "def build_lprnet(lpr_max_len=8, phase=False, class_num=66, dropout_rate=0.5):\n",
        "\n",
        "    Net = LPRNet(lpr_max_len, phase, class_num, dropout_rate)\n",
        "\n",
        "    if phase == \"train\":\n",
        "        return Net.train()\n",
        "    else:\n",
        "        return Net.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_drwD0Xoq4x",
        "outputId": "66bded31-52e1-4796-c47c-26cbc8c17dad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful to build network!\n"
          ]
        }
      ],
      "source": [
        "lprnet = build_lprnet(lpr_max_len=args.lpr_max_len, phase=args.phase_train, class_num=len(CHARS), dropout_rate=args.dropout_rate)\n",
        "device = torch.device(\"cuda:0\" if args.cuda else \"cpu\")\n",
        "lprnet.to(device)\n",
        "print(\"Successful to build network!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhQtv6jxVjIy",
        "outputId": "685470f6-a6f8-4411-dae5-a1d50ef7e2bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load pretrained model successful!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-2409f5438df2>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  lprnet.load_state_dict(torch.load(args.pretrained_model, map_location=torch.device('cpu')))\n"
          ]
        }
      ],
      "source": [
        "# load pretrained model\n",
        "if args.pretrained_model:\n",
        "    lprnet.load_state_dict(torch.load(args.pretrained_model, map_location=torch.device('cpu')))\n",
        "    print(\"load pretrained model successful!\")\n",
        "else:\n",
        "    print(\"[Error] Can't found pretrained mode, please check!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm-eJy501_ha"
      },
      "source": [
        "## Quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVktjGvPnczh",
        "outputId": "1bb1c0f9-122d-4c9e-c471-db40e4db6147"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LPRNet(\n",
              "  (backbone): Sequential(\n",
              "    (0): Conv2d(\n",
              "      3, 64, kernel_size=(3, 3), stride=(1, 1)\n",
              "      (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (1): BatchNorm2d(\n",
              "      64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): small_basic_block(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2d(\n",
              "          64, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "        (1): ReLU()\n",
              "        (2): Conv2d(\n",
              "          32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "        (3): ReLU()\n",
              "        (4): Conv2d(\n",
              "          32, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(\n",
              "          32, 128, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (5): BatchNorm2d(\n",
              "      128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (6): ReLU()\n",
              "    (7): MaxPool3d(kernel_size=(1, 3, 3), stride=(2, 1, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): small_basic_block(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2d(\n",
              "          64, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "        (1): ReLU()\n",
              "        (2): Conv2d(\n",
              "          64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "        (3): ReLU()\n",
              "        (4): Conv2d(\n",
              "          64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(\n",
              "          64, 256, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (9): BatchNorm2d(\n",
              "      256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (10): ReLU()\n",
              "    (11): small_basic_block(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2d(\n",
              "          256, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "        (1): ReLU()\n",
              "        (2): Conv2d(\n",
              "          64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "        (3): ReLU()\n",
              "        (4): Conv2d(\n",
              "          64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(\n",
              "          64, 256, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (12): BatchNorm2d(\n",
              "      256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (13): ReLU()\n",
              "    (14): MaxPool3d(kernel_size=(1, 3, 3), stride=(4, 1, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (15): Dropout(p=0, inplace=False)\n",
              "    (16): Conv2d(\n",
              "      64, 256, kernel_size=(1, 4), stride=(1, 1)\n",
              "      (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (17): BatchNorm2d(\n",
              "      256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (18): ReLU()\n",
              "    (19): Dropout(p=0, inplace=False)\n",
              "    (20): Conv2d(\n",
              "      256, 68, kernel_size=(13, 1), stride=(1, 1)\n",
              "      (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (21): BatchNorm2d(\n",
              "      68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (22): ReLU()\n",
              "  )\n",
              "  (container): Sequential(\n",
              "    (0): Conv2d(516, 68, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (quant): QuantStub(\n",
              "    (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (dequant): DeQuantStub()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "lprnet.eval()\n",
        "lprnet.qconfig = torch.ao.quantization.get_default_qconfig('x86')\n",
        "lprnet.container.qconfig = None\n",
        "lprnet_with_quant = torch.ao.quantization.prepare(lprnet)\n",
        "# Verify the structure\n",
        "lprnet_with_quant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vR-FJV53hWma"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    imgs = []\n",
        "    labels = []\n",
        "    lengths = []\n",
        "    for _, sample in enumerate(batch):\n",
        "        img, label, length = sample\n",
        "        imgs.append(torch.from_numpy(img))\n",
        "        labels.extend(label)\n",
        "        lengths.append(length)\n",
        "    labels = np.asarray(labels).flatten().astype(np.float32)\n",
        "\n",
        "    return (torch.stack(imgs, 0), torch.from_numpy(labels), lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FBJ1IJiYhWmb"
      },
      "outputs": [],
      "source": [
        "def Greedy_Decode_Eval(Net, datasets, args):\n",
        "    # TestNet = Net.eval()\n",
        "    epoch_size = len(datasets) // args.test_batch_size\n",
        "    batch_iterator = iter(DataLoader(datasets, args.test_batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=collate_fn))\n",
        "\n",
        "    Tp = 0\n",
        "    Tn_1 = 0\n",
        "    Tn_2 = 0\n",
        "    t1 = time.time()\n",
        "    for i in range(epoch_size):\n",
        "        # load train data\n",
        "        images, labels, lengths = next(batch_iterator)\n",
        "        start = 0\n",
        "        targets = []\n",
        "        for length in lengths:\n",
        "            label = labels[start:start+length]\n",
        "            targets.append(label)\n",
        "            start += length\n",
        "        targets = np.array([el.numpy() for el in targets])\n",
        "        imgs = images.numpy().copy()\n",
        "        print(imgs.shape)\n",
        "\n",
        "        if args.cuda:\n",
        "            images = Variable(images.cuda())\n",
        "        else:\n",
        "            images = Variable(images)\n",
        "\n",
        "        # forward\n",
        "        prebs = Net(images)\n",
        "        # greedy decode\n",
        "        prebs = prebs.cpu().detach().numpy()\n",
        "        preb_labels = list()\n",
        "        for i in range(prebs.shape[0]):\n",
        "            preb = prebs[i, :, :]\n",
        "            preb_label = list()\n",
        "            for j in range(preb.shape[1]):\n",
        "                preb_label.append(np.argmax(preb[:, j], axis=0))\n",
        "            no_repeat_blank_label = list()\n",
        "            pre_c = preb_label[0]\n",
        "            if pre_c != len(CHARS) - 1:\n",
        "                no_repeat_blank_label.append(pre_c)\n",
        "            for c in preb_label: # dropout repeate label and blank label\n",
        "                if (pre_c == c) or (c == len(CHARS) - 1):\n",
        "                    if c == len(CHARS) - 1:\n",
        "                        pre_c = c\n",
        "                    continue\n",
        "                no_repeat_blank_label.append(c)\n",
        "                pre_c = c\n",
        "            preb_labels.append(no_repeat_blank_label)\n",
        "        for i, label in enumerate(preb_labels):\n",
        "            # show image and its predict label\n",
        "            # if args.show:\n",
        "            #     show(imgs[i], label, targets[i])\n",
        "            if len(label) != len(targets[i]):\n",
        "                Tn_1 += 1\n",
        "                continue\n",
        "            if (np.asarray(targets[i]) == np.asarray(label)).all():\n",
        "                Tp += 1\n",
        "            else:\n",
        "                Tn_2 += 1\n",
        "    Acc = Tp * 1.0 / (Tp + Tn_1 + Tn_2)\n",
        "    print(\"[Info] Test Accuracy: {} [{}:{}:{}:{}]\".format(Acc, Tp, Tn_1, Tn_2, (Tp+Tn_1+Tn_2)))\n",
        "    t2 = time.time()\n",
        "    print(\"[Info] Test Speed: {}s 1/{}]\".format((t2 - t1) / len(datasets), len(datasets)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "D44OdfDmhWmc"
      },
      "outputs": [],
      "source": [
        "def test(model):\n",
        "    test_img_dirs = os.path.expanduser(args.test_img_dirs)\n",
        "    test_dataset = LPRDataLoader(test_img_dirs.split(','), args.img_size, args.lpr_max_len)\n",
        "    Greedy_Decode_Eval(model, test_dataset, args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk8ZQN_P_LiD",
        "outputId": "22761b0b-2e05-4a35-a5c6-10629ee6f147"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 3, 24, 94)\n",
            "in forward of lprnet\n",
            "(100, 3, 24, 94)\n",
            "in forward of lprnet\n",
            "(100, 3, 24, 94)\n",
            "in forward of lprnet\n",
            "(100, 3, 24, 94)\n",
            "in forward of lprnet\n",
            "(100, 3, 24, 94)\n",
            "in forward of lprnet\n",
            "(100, 3, 24, 94)\n",
            "in forward of lprnet\n",
            "(100, 3, 24, 94)\n",
            "in forward of lprnet\n",
            "(100, 3, 24, 94)\n",
            "in forward of lprnet\n",
            "(100, 3, 24, 94)\n",
            "in forward of lprnet\n",
            "(100, 3, 24, 94)\n",
            "in forward of lprnet\n",
            "[Info] Test Accuracy: 0.895 [895:70:35:1000]\n",
            "[Info] Test Speed: 0.05241087055206299s 1/1000]\n"
          ]
        }
      ],
      "source": [
        "test(lprnet_with_quant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT4wRy2-hv42",
        "outputId": "c0a045a8-8be4-4cde-d308-dbbe0727511f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LPRNet(\n",
              "  (backbone): Sequential(\n",
              "    (0): Conv2d(\n",
              "      3, 64, kernel_size=(3, 3), stride=(1, 1)\n",
              "      (activation_post_process): HistogramObserver(min_val=-24.24433135986328, max_val=32.877845764160156)\n",
              "    )\n",
              "    (1): BatchNorm2d(\n",
              "      64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (activation_post_process): HistogramObserver(min_val=-53.673240661621094, max_val=38.9561767578125)\n",
              "    )\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): small_basic_block(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2d(\n",
              "          64, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (activation_post_process): HistogramObserver(min_val=-36.72121047973633, max_val=32.40449142456055)\n",
              "        )\n",
              "        (1): ReLU()\n",
              "        (2): Conv2d(\n",
              "          32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0)\n",
              "          (activation_post_process): HistogramObserver(min_val=-78.62523651123047, max_val=66.64794921875)\n",
              "        )\n",
              "        (3): ReLU()\n",
              "        (4): Conv2d(\n",
              "          32, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1)\n",
              "          (activation_post_process): HistogramObserver(min_val=-145.69960021972656, max_val=314.0687255859375)\n",
              "        )\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(\n",
              "          32, 128, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (activation_post_process): HistogramObserver(min_val=-372.82073974609375, max_val=315.5547180175781)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (5): BatchNorm2d(\n",
              "      128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (activation_post_process): HistogramObserver(min_val=-317.0633850097656, max_val=155.93722534179688)\n",
              "    )\n",
              "    (6): ReLU()\n",
              "    (7): MaxPool3d(kernel_size=(1, 3, 3), stride=(2, 1, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): small_basic_block(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2d(\n",
              "          64, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (activation_post_process): HistogramObserver(min_val=-79.48235321044922, max_val=93.69741821289062)\n",
              "        )\n",
              "        (1): ReLU()\n",
              "        (2): Conv2d(\n",
              "          64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0)\n",
              "          (activation_post_process): HistogramObserver(min_val=-112.94474029541016, max_val=166.30685424804688)\n",
              "        )\n",
              "        (3): ReLU()\n",
              "        (4): Conv2d(\n",
              "          64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1)\n",
              "          (activation_post_process): HistogramObserver(min_val=-208.36407470703125, max_val=245.1654815673828)\n",
              "        )\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(\n",
              "          64, 256, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (activation_post_process): HistogramObserver(min_val=-309.18585205078125, max_val=291.06268310546875)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (9): BatchNorm2d(\n",
              "      256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (activation_post_process): HistogramObserver(min_val=-25.163881301879883, max_val=31.005788803100586)\n",
              "    )\n",
              "    (10): ReLU()\n",
              "    (11): small_basic_block(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2d(\n",
              "          256, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (activation_post_process): HistogramObserver(min_val=-17.522907257080078, max_val=41.133644104003906)\n",
              "        )\n",
              "        (1): ReLU()\n",
              "        (2): Conv2d(\n",
              "          64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0)\n",
              "          (activation_post_process): HistogramObserver(min_val=-39.86260986328125, max_val=34.64474105834961)\n",
              "        )\n",
              "        (3): ReLU()\n",
              "        (4): Conv2d(\n",
              "          64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1)\n",
              "          (activation_post_process): HistogramObserver(min_val=-30.264240264892578, max_val=48.38500213623047)\n",
              "        )\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(\n",
              "          64, 256, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (activation_post_process): HistogramObserver(min_val=-50.667964935302734, max_val=141.88560485839844)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (12): BatchNorm2d(\n",
              "      256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (activation_post_process): HistogramObserver(min_val=-35.38861083984375, max_val=314.27716064453125)\n",
              "    )\n",
              "    (13): ReLU()\n",
              "    (14): MaxPool3d(kernel_size=(1, 3, 3), stride=(4, 1, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (15): Dropout(p=0, inplace=False)\n",
              "    (16): Conv2d(\n",
              "      64, 256, kernel_size=(1, 4), stride=(1, 1)\n",
              "      (activation_post_process): HistogramObserver(min_val=-10.991701126098633, max_val=12.590535163879395)\n",
              "    )\n",
              "    (17): BatchNorm2d(\n",
              "      256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (activation_post_process): HistogramObserver(min_val=-8.491602897644043, max_val=7.412395477294922)\n",
              "    )\n",
              "    (18): ReLU()\n",
              "    (19): Dropout(p=0, inplace=False)\n",
              "    (20): Conv2d(\n",
              "      256, 68, kernel_size=(13, 1), stride=(1, 1)\n",
              "      (activation_post_process): HistogramObserver(min_val=-16.994583129882812, max_val=15.233458518981934)\n",
              "    )\n",
              "    (21): BatchNorm2d(\n",
              "      68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (activation_post_process): HistogramObserver(min_val=-9.460067749023438, max_val=10.605412483215332)\n",
              "    )\n",
              "    (22): ReLU()\n",
              "  )\n",
              "  (container): Sequential(\n",
              "    (0): Conv2d(516, 68, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (quant): QuantStub(\n",
              "    (activation_post_process): HistogramObserver(min_val=-0.99609375, max_val=0.99609375)\n",
              "  )\n",
              "  (dequant): DeQuantStub()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "lprnet_with_quant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uMLOf2rDDfO1"
      },
      "outputs": [],
      "source": [
        "lprnet_with_quant = torch.ao.quantization.convert(lprnet_with_quant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPF8fxwCDfa3",
        "outputId": "1b0ab5ee-3492-40de-ca0b-252ae24d09aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check statistics of the various layers\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LPRNet(\n",
              "  (backbone): Sequential(\n",
              "    (0): QuantizedConv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.3160325884819031, zero_point=56)\n",
              "    (1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): small_basic_block(\n",
              "      (block): Sequential(\n",
              "        (0): QuantizedConv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.4220426678657532, zero_point=71)\n",
              "        (1): ReLU()\n",
              "        (2): QuantizedConv2d(32, 32, kernel_size=(3, 1), stride=(1, 1), scale=0.8657320141792297, zero_point=70, padding=(1, 0))\n",
              "        (3): ReLU()\n",
              "        (4): QuantizedConv2d(32, 32, kernel_size=(1, 3), stride=(1, 1), scale=2.7328438758850098, zero_point=42, padding=(0, 1))\n",
              "        (5): ReLU()\n",
              "        (6): QuantizedConv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), scale=3.644397020339966, zero_point=65)\n",
              "      )\n",
              "    )\n",
              "    (5): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU()\n",
              "    (7): MaxPool3d(kernel_size=(1, 3, 3), stride=(2, 1, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): small_basic_block(\n",
              "      (block): Sequential(\n",
              "        (0): QuantizedConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.8542602062225342, zero_point=60)\n",
              "        (1): ReLU()\n",
              "        (2): QuantizedConv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), scale=1.3774904012680054, zero_point=52, padding=(1, 0))\n",
              "        (3): ReLU()\n",
              "        (4): QuantizedConv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), scale=2.4307186603546143, zero_point=58, padding=(0, 1))\n",
              "        (5): ReLU()\n",
              "        (6): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=3.4432318210601807, zero_point=42)\n",
              "      )\n",
              "    )\n",
              "    (9): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): ReLU()\n",
              "    (11): small_basic_block(\n",
              "      (block): Sequential(\n",
              "        (0): QuantizedConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.3136967420578003, zero_point=56)\n",
              "        (1): ReLU()\n",
              "        (2): QuantizedConv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), scale=0.38271188735961914, zero_point=68, padding=(1, 0))\n",
              "        (3): ReLU()\n",
              "        (4): QuantizedConv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), scale=0.427573025226593, zero_point=52, padding=(0, 1))\n",
              "        (5): ReLU()\n",
              "        (6): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.9668543934822083, zero_point=33)\n",
              "      )\n",
              "    )\n",
              "    (12): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (13): ReLU()\n",
              "    (14): MaxPool3d(kernel_size=(1, 3, 3), stride=(4, 1, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (15): QuantizedDropout(p=0, inplace=False)\n",
              "    (16): QuantizedConv2d(64, 256, kernel_size=(1, 4), stride=(1, 1), scale=0.1483319252729416, zero_point=74)\n",
              "    (17): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (18): ReLU()\n",
              "    (19): QuantizedDropout(p=0, inplace=False)\n",
              "    (20): QuantizedConv2d(256, 68, kernel_size=(13, 1), stride=(1, 1), scale=0.21299828588962555, zero_point=68)\n",
              "    (21): QuantizedBatchNorm2d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU()\n",
              "  )\n",
              "  (container): Sequential(\n",
              "    (0): Conv2d(516, 68, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (quant): Quantize(scale=tensor([0.0157]), zero_point=tensor([64]), dtype=torch.quint8)\n",
              "  (dequant): DeQuantize()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "print(f'Check statistics of the various layers')\n",
        "lprnet_with_quant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSRuuK5CDfk_",
        "outputId": "5b4cd11b-6cf0-49b4-bd73-8ca6d4f5f2a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights after quantization\n",
            "tensor([[ 83, 127,  27],\n",
            "        [ 40,  27,  17],\n",
            "        [ 20,  37, -11]], dtype=torch.int8)\n"
          ]
        }
      ],
      "source": [
        "# Print the weights matrix of the model after quantization\n",
        "print('Weights after quantization')\n",
        "print(torch.int_repr(lprnet_with_quant.backbone[0].weight()[0][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PK4DcYvEzvZ",
        "outputId": "1cd5ee83-19f7-4cde-d43d-226cf4211437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original weights: \n",
            "tensor([[ 0.6627,  1.0154,  0.2187],\n",
            "        [ 0.3205,  0.2122,  0.1328],\n",
            "        [ 0.1622,  0.2951, -0.0841]], grad_fn=<SelectBackward0>)\n",
            "\n",
            "Dequantized weights: \n",
            "tensor([[ 0.6610,  1.0115,  0.2150],\n",
            "        [ 0.3186,  0.2150,  0.1354],\n",
            "        [ 0.1593,  0.2947, -0.0876]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Original weights: ')\n",
        "print(lprnet.backbone[0].weight[0][0])\n",
        "print('')\n",
        "print(f'Dequantized weights: ')\n",
        "print(torch.dequantize(lprnet_with_quant.backbone[0].weight()[0][0]))\n",
        "print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "h4Kjj8G95eXK"
      },
      "outputs": [],
      "source": [
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"temp_delme.p\")\n",
        "    print('Size (KB):', os.path.getsize(\"temp_delme.p\")/1e3)\n",
        "    os.remove('temp_delme.p')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gH1H89mtFk3X",
        "outputId": "10619e6e-0e94-4705-9f97-00afbda0ef38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the model before quantization\n",
            "Size (KB): 1816.802\n",
            "Size of the model after quantization\n",
            "Size (KB): 637.382\n"
          ]
        }
      ],
      "source": [
        "print('Size of the model before quantization')\n",
        "print_size_of_model(lprnet)\n",
        "print('Size of the model after quantization')\n",
        "print_size_of_model(lprnet_with_quant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7yzaiZ9h9EG",
        "outputId": "0cde97b3-8c47-4695-95f1-265b6baff753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing the model after quantization\n",
            "(100, 3, 24, 94)\n",
            "in forward of lprnet\n",
            "(100, 3, 24, 94)\n",
            "in forward of lprnet\n",
            "(100, 3, 24, 94)\n",
            "in forward of lprnet\n",
            "(100, 3, 24, 94)\n",
            "in forward of lprnet\n",
            "(100, 3, 24, 94)\n",
            "in forward of lprnet\n",
            "(100, 3, 24, 94)\n",
            "in forward of lprnet\n",
            "(100, 3, 24, 94)\n",
            "in forward of lprnet\n",
            "(100, 3, 24, 94)\n",
            "in forward of lprnet\n",
            "(100, 3, 24, 94)\n",
            "in forward of lprnet\n",
            "(100, 3, 24, 94)\n",
            "in forward of lprnet\n",
            "[Info] Test Accuracy: 0.844 [844:94:62:1000]\n",
            "[Info] Test Speed: 0.025954334020614624s 1/1000]\n"
          ]
        }
      ],
      "source": [
        "print('Testing the model after quantization')\n",
        "test(lprnet_with_quant)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g363inswfbge"
      },
      "source": [
        "## Save Quantized Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "r4Y2kL6GMRp1"
      },
      "outputs": [],
      "source": [
        "torch.save(lprnet_with_quant.state_dict(), './weights/lprnet_ptsq_and_pruning_weights.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1JyLWBSmx0UH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}